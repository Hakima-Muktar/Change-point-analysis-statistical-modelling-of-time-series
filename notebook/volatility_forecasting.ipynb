{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea42e597",
   "metadata": {},
   "source": [
    "### 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c7bc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✓ Libraries loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43459f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../data/raw/BrentOilPrices.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='mixed', dayfirst=True)\n",
    "df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "# Focus on 2012-2022\n",
    "df_recent = df[df['Date'] >= '2012-01-01'].copy()\n",
    "\n",
    "# Calculate log returns\n",
    "df_recent['Log_Return'] = np.log(df_recent['Price'] / df_recent['Price'].shift(1))\n",
    "df_recent = df_recent.dropna()\n",
    "\n",
    "returns = df_recent['Log_Return'].values\n",
    "dates = df_recent['Date'].values\n",
    "\n",
    "print(f\"Data: {len(returns)} observations\")\n",
    "print(f\"Returns stats: Mean={returns.mean():.5f}, Std={returns.std():.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa3fd9",
   "metadata": {},
   "source": [
    "### 2. Volatility Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2463a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "ax[0].plot(dates, returns, alpha=0.6, label='Log Returns')\n",
    "ax[0].set_title('Brent Oil Log Returns (2012-2022)')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(dates, returns**2, alpha=0.6, color='orange', label='Squared Returns')\n",
    "ax[1].set_title('Volatility Clustering (Squared Returns)')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/volatility_clustering.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8427b64f",
   "metadata": {},
   "source": [
    "### 3. Bayesian Stochastic Volatility Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d8b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize returns for better convergence\n",
    "returns_std = (returns - returns.mean()) / returns.std()\n",
    "\n",
    "with pm.Model() as sv_model:\n",
    "    # Nu (degrees of freedom) for heavy tails\n",
    "    nu = pm.Exponential('nu', 0.1)\n",
    "    \n",
    "    # Volatility process standard deviation\n",
    "    sigma = pm.Exponential('sigma', 10.0)\n",
    "    \n",
    "    # Latent log volatility process (Gaussian Random Walk)\n",
    "    # Latent log volatility process (Gaussian Random Walk)\n",
    "    # Manual implementation to avoid PyTensor OverflowError\n",
    "    step_s = pm.Normal('step_s', 0.0, sigma=sigma, shape=len(returns))\n",
    "    s = pm.Deterministic('s', step_s.cumsum())\n",
    "    \n",
    "    # Likelihood\n",
    "    # exp(s) is the volatility (scale)\n",
    "    r = pm.StudentT('r', nu=nu, mu=0, sigma=pm.math.exp(s), observed=returns_std)\n",
    "\n",
    "print(\"✓ Stochastic Volatility Model built\")\n",
    "# print(pm.model_to_graphviz(sv_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53e1eb3",
   "metadata": {},
   "source": [
    "### 4. Latent Volatility Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd65488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract posterior of log volatility 's'\n",
    "posterior_s = trace_sv.posterior['s'].mean(dim=['chain', 'draw']).values\n",
    "\n",
    "# Convert back to original scale standard deviation\n",
    "# volatility = exp(s) * original_std\n",
    "volatility_estimated = np.exp(posterior_s) * returns.std()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.plot(dates, np.abs(returns), alpha=0.5, label='Absolute Returns', color='gray', lw=1)\n",
    "ax.plot(dates, volatility_estimated, label='Estimated Stochastic Volatility', color='red', lw=2)\n",
    "ax.set_title('Estimated Volatility (Bayesian Stochastic Volatility Model)')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/estimated_stochastic_volatility.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e29165",
   "metadata": {},
   "source": [
    "### 5. Insight: High Volatility Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fe2b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe of estimated volatility\n",
    "vol_df = pd.DataFrame({'Date': dates, 'Volatility': volatility_estimated})\n",
    "\n",
    "# Find top 5 high volatility periods\n",
    "top_vol = vol_df.sort_values('Volatility', ascending=False).head(10)\n",
    "print(\"Top High Volatility Dates:\")\n",
    "print(top_vol)\n",
    "\n",
    "# Save volatility data\n",
    "vol_df.to_csv('../data/processed/stochastic_volatility_estimates.csv', index=False)\n",
    "print(\"✓ Volatility estimates saved\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
